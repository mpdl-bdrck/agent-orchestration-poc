"""
CSV File Management for Chainlit UI.

Handles storage, retrieval, and sending of CSV files generated by tools.
Uses multiple fallback mechanisms to ensure CSV data survives module reloads.
"""
import json
import os
import sys
import tempfile
import glob
import importlib
import logging

import chainlit as cl

from .config import _GLOBAL_CSV_STORAGE

logger = logging.getLogger(__name__)


def retrieve_csv_from_session(node_name: str = None) -> tuple[str | None, str | None]:
    """
    Retrieve CSV data from Chainlit session storage.
    
    Args:
        node_name: Optional node name to filter by
        
    Returns:
        Tuple of (csv_data, csv_filename) or (None, None) if not found
    """
    csv_attachments = cl.user_session.get("csv_attachments", {})
    logger.info(f"ðŸ” Checking session CSV attachments: {list(csv_attachments.keys())}")
    
    for tool_name, csv_info in csv_attachments.items():
        if node_name is None or csv_info.get("node_name") == node_name:
            csv_data = csv_info.get("csv")
            csv_filename = csv_info.get("filename")
            if csv_data and csv_filename:
                logger.info(f"âœ… Found CSV in session storage: filename={csv_filename}")
                return csv_data, csv_filename
    
    return None, None


def retrieve_csv_from_file_cache(node_name: str = None) -> tuple[str | None, str | None]:
    """
    Retrieve CSV data from file-based cache (survives module reloads).
    
    Args:
        node_name: Optional node name to filter by
        
    Returns:
        Tuple of (csv_data, csv_filename) or (None, None) if not found
    """
    try:
        cache_dir = os.path.join(tempfile.gettempdir(), "chainlit_csv_cache")
        if not os.path.exists(cache_dir):
            return None, None
        
        # Build pattern based on node_name
        if node_name:
            pattern = os.path.join(cache_dir, f"*{node_name}*analyze_portfolio_pacing*.json")
        else:
            pattern = os.path.join(cache_dir, "*guardian*analyze_portfolio_pacing*.json")
        
        cache_files = glob.glob(pattern)
        logger.info(f"ðŸ” File cache check: found {len(cache_files)} cache files")
        
        for cache_file in cache_files:
            try:
                with open(cache_file, 'r') as f:
                    csv_info = json.load(f)
                    csv_data = csv_info.get("csv")
                    csv_filename = csv_info.get("filename")
                    if csv_data and csv_filename:
                        logger.info(f"âœ… Found CSV in file cache: {cache_file}, filename={csv_filename}")
                        
                        # Store in session for next time
                        csv_attachments = cl.user_session.get("csv_attachments", {})
                        csv_attachments["analyze_portfolio_pacing"] = {
                            "csv": csv_data,
                            "filename": csv_filename,
                            "node_name": csv_info.get("node_name", node_name or "guardian")
                        }
                        cl.user_session.set("csv_attachments", csv_attachments)
                        
                        # Also store in global storage
                        _GLOBAL_CSV_STORAGE[os.path.basename(cache_file)] = csv_info
                        
                        # Delete cache file after reading
                        try:
                            os.remove(cache_file)
                        except Exception:
                            pass
                        
                        return csv_data, csv_filename
            except Exception as e:
                logger.debug(f"Error reading cache file {cache_file}: {e}")
        
        return None, None
    except Exception as e:
        logger.debug(f"Could not access file cache: {e}")
        return None, None


def retrieve_csv_from_global_storage(node_name: str = None) -> tuple[str | None, str | None]:
    """
    Retrieve CSV data from global storage dictionary.
    
    Args:
        node_name: Optional node name to filter by (e.g., "guardian")
        
    Returns:
        Tuple of (csv_data, csv_filename) or (None, None) if not found
    """
    try:
        logger.info(f"ðŸ” Global storage keys: {list(_GLOBAL_CSV_STORAGE.keys())}")
        for storage_key, csv_info in _GLOBAL_CSV_STORAGE.items():
            if "analyze_portfolio_pacing" in storage_key:
                # FILTER BY NODE_NAME if provided - only return CSV for the correct agent
                stored_node_name = csv_info.get("node_name", "guardian")
                if node_name and stored_node_name != node_name:
                    logger.debug(f"ðŸ” Skipping CSV in global storage: stored_node={stored_node_name}, requested_node={node_name}")
                    continue  # Skip if node_name doesn't match
                
                csv_data = csv_info.get("csv")
                csv_filename = csv_info.get("filename")
                if csv_data and csv_filename:
                    logger.info(f"âœ… Found CSV in global storage: filename={csv_filename}, node_name={stored_node_name}")
                    
                    # Store in session for next time
                    csv_attachments = cl.user_session.get("csv_attachments", {})
                    csv_attachments["analyze_portfolio_pacing"] = {
                        "csv": csv_data,
                        "filename": csv_filename,
                        "node_name": stored_node_name
                    }
                    cl.user_session.set("csv_attachments", csv_attachments)
                    
                    return csv_data, csv_filename
        
        return None, None
    except Exception as e:
        logger.error(f"âŒ Error accessing global storage: {e}", exc_info=True)
        return None, None


def retrieve_csv_from_module_storage(node_name: str = None) -> tuple[str | None, str | None]:
    """
    Retrieve CSV data from module-level storage (execute_agent_loop._csv_storage).
    
    Args:
        node_name: Optional node name to filter by (defaults to "guardian")
        
    Returns:
        Tuple of (csv_data, csv_filename) or (None, None) if not found
    """
    if node_name is None:
        node_name = "guardian"
    
    try:
        module_name = 'src.utils.agent_loop'
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
        
        if project_root not in sys.path:
            sys.path.insert(0, project_root)
        
        execute_agent_loop = None
        
        # Method 1: Search ALL modules for execute_agent_loop with _csv_storage
        logger.info(f"ðŸ” Searching all modules for execute_agent_loop with _csv_storage...")
        modules_checked = 0
        for mod_name, mod in sys.modules.items():
            if mod is None:
                continue
            modules_checked += 1
            try:
                if hasattr(mod, 'execute_agent_loop'):
                    candidate_func = getattr(mod, 'execute_agent_loop')
                    if hasattr(candidate_func, '_csv_storage'):
                        storage_dict = getattr(candidate_func, '_csv_storage', {})
                        if isinstance(storage_dict, dict) and len(storage_dict) > 0:
                            execute_agent_loop = candidate_func
                            logger.info(f"âœ… Found execute_agent_loop with _csv_storage in module: {mod_name}, keys: {list(storage_dict.keys())}")
                            break
            except Exception as e:
                logger.debug(f"Error checking module {mod_name}: {e}")
                continue
        
        logger.info(f"ðŸ” Searched {modules_checked} modules")
        
        # Method 2: Try direct lookup
        if not execute_agent_loop and module_name in sys.modules:
            agent_loop_module = sys.modules[module_name]
            if hasattr(agent_loop_module, 'execute_agent_loop'):
                candidate_func = getattr(agent_loop_module, 'execute_agent_loop')
                if hasattr(candidate_func, '_csv_storage'):
                    execute_agent_loop = candidate_func
                    logger.info(f"âœ… Found execute_agent_loop in sys.modules!")
        
        # Method 3: Try importing
        if not execute_agent_loop:
            try:
                agent_loop_module = importlib.import_module(module_name)
                if hasattr(agent_loop_module, 'execute_agent_loop'):
                    candidate_func = getattr(agent_loop_module, 'execute_agent_loop')
                    if hasattr(candidate_func, '_csv_storage'):
                        execute_agent_loop = candidate_func
                        logger.info(f"âœ… Module imported and execute_agent_loop found!")
            except ImportError as e_import:
                logger.warning(f"âš ï¸ Standard import failed ({e_import})")
            except Exception as e_import:
                logger.error(f"âŒ Failed to import module: {e_import}", exc_info=True)
        
        # Retrieve CSV from storage
        if execute_agent_loop and hasattr(execute_agent_loop, '_csv_storage'):
            storage_keys = list(execute_agent_loop._csv_storage.keys())
            logger.info(f"âœ… CSV storage exists! Keys: {storage_keys}")
            
            for storage_key, csv_info in execute_agent_loop._csv_storage.items():
                if node_name == "guardian" and "analyze_portfolio_pacing" in storage_key:
                    csv_data = csv_info.get("csv")
                    csv_filename = csv_info.get("filename")
                    if csv_data and csv_filename:
                        logger.info(f"âœ… Found CSV in module storage! filename={csv_filename}, csv_len={len(csv_data)}")
                        
                        # Store in session and global storage for next time
                        csv_attachments = cl.user_session.get("csv_attachments", {})
                        csv_attachments["analyze_portfolio_pacing"] = {
                            "csv": csv_data,
                            "filename": csv_filename,
                            "node_name": node_name
                        }
                        cl.user_session.set("csv_attachments", csv_attachments)
                        _GLOBAL_CSV_STORAGE[storage_key] = {
                            "csv": csv_data,
                            "filename": csv_filename,
                            "node_name": node_name
                        }
                        
                        return csv_data, csv_filename
        
        return None, None
    except Exception as e:
        logger.error(f"âŒ Error accessing module storage: {e}", exc_info=True)
        return None, None


def retrieve_csv_all_methods(node_name: str = None) -> tuple[str | None, str | None]:
    """
    Try all CSV retrieval methods in order of reliability.
    
    Args:
        node_name: Optional node name to filter by
        
    Returns:
        Tuple of (csv_data, csv_filename) or (None, None) if not found
    """
    logger.info(f"ðŸ” Starting CSV retrieval for node: {node_name}")
    
    # Method 1: Session storage (most reliable)
    csv_data, csv_filename = retrieve_csv_from_session(node_name)
    if csv_data and csv_filename:
        return csv_data, csv_filename
    
    # Method 2: File cache (survives reloads)
    csv_data, csv_filename = retrieve_csv_from_file_cache(node_name)
    if csv_data and csv_filename:
        return csv_data, csv_filename
    
    # Method 3: Global storage (with node_name filtering)
    csv_data, csv_filename = retrieve_csv_from_global_storage(node_name)
    if csv_data and csv_filename:
        return csv_data, csv_filename
    
    # Method 4: Module storage
    csv_data, csv_filename = retrieve_csv_from_module_storage(node_name)
    if csv_data and csv_filename:
        return csv_data, csv_filename
    
    logger.info(f"ðŸ” No CSV found using any method")
    return None, None


async def send_csv_as_message(csv_data: str, csv_filename: str) -> None:
    """
    Send CSV file as a new Chainlit message (Late Arrival Pattern).
    
    Args:
        csv_data: CSV content as string
        csv_filename: Filename for the CSV file
    """
    try:
        csv_bytes = csv_data.encode("utf-8")
        logger.info(f"ðŸ” Creating CSV file element: filename={csv_filename}, size={len(csv_bytes)} bytes")
        
        # Save CSV to temporary file (Chainlit may prefer path over content)
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as tmp_file:
            tmp_file.write(csv_data)
            tmp_path = tmp_file.name
        
        logger.info(f"ðŸ” CSV saved to temp file: {tmp_path}")
        
        # Try using path instead of content (Chainlit may prefer file paths)
        try:
            csv_element = cl.File(
                name=csv_filename,
                path=tmp_path,
                display="inline"
            )
            logger.info(f"ðŸ” CSV element created with path: {csv_element}")
        except (TypeError, AttributeError, Exception) as e:
            # Fallback to content if path doesn't work
            logger.warning(f"ðŸ” Path failed ({e}), trying content instead...")
            csv_element = cl.File(
                name=csv_filename,
                content=csv_bytes,
                display="inline"
            )
            logger.info(f"ðŸ” CSV element created with content: {csv_element}")
        
        # Send a BRAND NEW message with the CSV file
        # This guarantees a fresh render cycle - frontend MUST draw the file
        csv_message = cl.Message(
            content=f"ðŸ“Š **Download:** {csv_filename}",
            elements=[csv_element],
            author="System"
        )
        
        logger.info(f"ðŸ” CSV message created, sending...")
        await csv_message.send()
        logger.info(f"âœ…âœ…âœ… CSV file sent as new message: {csv_filename} (message ID: {getattr(csv_message, 'id', 'unknown')})")
        
    except Exception as e:
        logger.error(f"Failed to send CSV as new message: {e}", exc_info=True)


def store_csv_in_session(csv_data: str, csv_filename: str, tool_name: str, node_name: str) -> None:
    """
    Store CSV data in Chainlit session for later retrieval.
    
    Args:
        csv_data: CSV content as string
        csv_filename: Filename for the CSV file
        tool_name: Name of the tool that generated the CSV
        node_name: Name of the node/agent that called the tool
    """
    csv_attachments = cl.user_session.get("csv_attachments", {})
    csv_attachments[tool_name] = {
        "csv": csv_data,
        "filename": csv_filename,
        "node_name": node_name
    }
    cl.user_session.set("csv_attachments", csv_attachments)
    logger.info(f"âœ… Stored CSV in session: {csv_filename}")


def clear_csv_storage(node_name: str = None) -> None:
    """
    Clear CSV data from all storage locations to prevent duplicates.
    
    Args:
        node_name: Optional node name to filter clearing (if None, clears all)
    """
    try:
        # 1. Clear session storage
        try:
            csv_attachments = cl.user_session.get("csv_attachments", {})
            if node_name:
                # Clear only for this node
                for tool_name, csv_info in list(csv_attachments.items()):
                    if csv_info.get("node_name") == node_name:
                        del csv_attachments[tool_name]
                        logger.debug(f"Cleared CSV from session: {tool_name} for {node_name}")
            else:
                # Clear all
                csv_attachments.clear()
                logger.debug("Cleared all CSV from session")
            cl.user_session.set("csv_attachments", csv_attachments)
        except Exception as e:
            logger.debug(f"Could not clear session CSV storage: {e}")
        
        # 2. Clear global storage
        try:
            if node_name:
                # Clear only for this node
                for key in list(_GLOBAL_CSV_STORAGE.keys()):
                    csv_info = _GLOBAL_CSV_STORAGE.get(key, {})
                    if csv_info.get("node_name") == node_name and "analyze_portfolio_pacing" in key:
                        del _GLOBAL_CSV_STORAGE[key]
                        logger.debug(f"Cleared CSV from global storage: {key} for {node_name}")
            else:
                # Clear all
                keys_to_remove = [k for k in _GLOBAL_CSV_STORAGE.keys() if "analyze_portfolio_pacing" in k]
                for key in keys_to_remove:
                    del _GLOBAL_CSV_STORAGE[key]
                logger.debug(f"Cleared {len(keys_to_remove)} CSV entries from global storage")
        except Exception as e:
            logger.debug(f"Could not clear global CSV storage: {e}")
        
        # 3. Clear module storage
        try:
            try:
                from src.utils.agent_loop import execute_agent_loop
            except ImportError:
                # Fallback: ensure project root is in path, then try importing
                project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
                if project_root not in sys.path:
                    sys.path.insert(0, project_root)
                
                if 'src.utils.agent_loop' in sys.modules:
                    execute_agent_loop = sys.modules['src.utils.agent_loop'].execute_agent_loop
                else:
                    agent_loop_module = importlib.import_module('src.utils.agent_loop')
                    execute_agent_loop = agent_loop_module.execute_agent_loop
            
            if hasattr(execute_agent_loop, '_csv_storage'):
                if node_name:
                    # Clear only for this node
                    for key in list(execute_agent_loop._csv_storage.keys()):
                        csv_info = execute_agent_loop._csv_storage.get(key, {})
                        if csv_info.get("node_name") == node_name and "analyze_portfolio_pacing" in key:
                            del execute_agent_loop._csv_storage[key]
                            logger.debug(f"Cleared CSV from module storage: {key} for {node_name}")
                else:
                    # Clear all
                    keys_to_remove = [k for k in execute_agent_loop._csv_storage.keys() if "analyze_portfolio_pacing" in k]
                    for key in keys_to_remove:
                        del execute_agent_loop._csv_storage[key]
                    logger.debug(f"Cleared {len(keys_to_remove)} CSV entries from module storage")
        except Exception as e:
            logger.debug(f"Could not clear module CSV storage: {e}")
    except Exception as e:
        logger.debug(f"Could not clear CSV storage: {e}")

