# Specialist Agent Configuration
agent_id: "specialist"
agent_name: "Specialist Agent"
agent_type: "specialist"
version: "1.0.0"

# LLM Configuration
llm:
  provider: "gemini"
  model: "gemini-2.5-flash"  # Inherits from config.yaml default, can override here
  temperature: 0.7
  max_tokens: 2000

# Prompt Templates
prompts:
  system: "prompts/specialist_agent/system.txt"
  user: "prompts/specialist_agent/user.txt"

# Input/Output Fields
input_fields:
  - "question"
  - "context"

output_fields:
  - "answer"
  - "analysis"

# Validation Rules
validation:
  required_fields:
    - "answer"

